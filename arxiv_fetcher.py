import arxiv
from datetime import datetime, timedelta
from typing import List, Dict
import logging
from config import Config

logger = logging.getLogger(__name__)

class ArxivFetcher:
    def __init__(self):
        self.client = arxiv.Client()
        self.keywords = Config.SEARCH_KEYWORDS
        
    def fetch_recent_papers(self, days_back: int = 1) -> List[Dict]:
        """
        èŽ·å–æœ€è¿‘å‡ å¤©çš„è®ºæ–‡
        
        Args:
            days_back: å›žæº¯å¤©æ•°ï¼Œé»˜è®¤ä¸º1ï¼ˆèŽ·å–æ˜¨å¤©çš„ï¼‰
        """
        try:
            days_back = 3
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)
            
            # æž„å»ºæŸ¥è¯¢
            date_range = f"[{start_date.strftime('%Y%m%d')} TO {end_date.strftime('%Y%m%d')}]"
            keyword_query = " OR ".join([f'abs:"{kw.strip()}"' for kw in self.keywords])
            query = f"({keyword_query}) AND submittedDate:{date_range}"
            
            logger.info(f"æœç´¢æŸ¥è¯¢: {query}")
            
            # æœç´¢è®ºæ–‡
            search = arxiv.Search(
                query=query,
                max_results=Config.MAX_RESULTS,
                sort_by=arxiv.SortCriterion.SubmittedDate,
                sort_order=arxiv.SortOrder.Descending
            )
            
            papers = []
            for result in self.client.results(search):
                paper = {
                    'id': result.get_short_id(),
                    'title': result.title,
                    'authors': [author.name for author in result.authors],
                    'abstract': result.summary,
                    'pdf_url': result.pdf_url,
                    'published': result.published.strftime('%Y-%m-%d %H:%M'),
                    'primary_category': result.primary_category,
                    'categories': result.categories,
                    'arxiv_url': result.entry_id,
                }
                papers.append(paper)
                logger.info(f"æ‰¾åˆ°è®ºæ–‡: {paper['title'][:50]}...")
            
            logger.info(f"å…±æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡")
            return papers
            
        except Exception as e:
            logger.error(f"èŽ·å–è®ºæ–‡å¤±è´¥: {e}")
            return []
    
    def generate_summary(self, paper: Dict) -> str:
        """ç”Ÿæˆè®ºæ–‡çš„ä¸­æ–‡æ‘˜è¦"""
        title = paper['title']
        abstract = paper['abstract']
        
        # ç®€å•æ€»ç»“é€»è¾‘ï¼ˆåŽç»­å¯ä»¥æŽ¥å…¥AIï¼‰
        summary_lines = [
            "=" * 60,
            f"ðŸ“„ æ ‡é¢˜: {title}",
            "",
            f"ðŸ‘¥ ä½œè€…: {', '.join(paper['authors'][:3])}{'ç­‰' if len(paper['authors']) > 3 else ''}",
            f"ðŸ“… å‘å¸ƒæ—¶é—´: {paper['published']}",
            f"ðŸ“š åˆ†ç±»: {paper['primary_category']}",
            "",
            "ðŸ“ æ‘˜è¦æ‘˜è¦:",
            self._truncate_text(abstract, 800) + ("..." if len(abstract) > 800 else ""),
            "",
            "ðŸ”— é“¾æŽ¥:",
            f"PDF: {paper['pdf_url']}",
            f"Arxiv: {paper['arxiv_url']}",
            "=" * 60,
            ""
        ]
        
        return "\n".join(summary_lines)
    
    def _truncate_text(self, text: str, max_length: int) -> str:
        """æˆªæ–­æ–‡æœ¬"""
        if len(text) <= max_length:
            return text
        return text[:max_length].rsplit(' ', 1)[0]  # åœ¨æœ€åŽä¸€ä¸ªç©ºæ ¼å¤„æˆªæ–­
